import streamlit as st
import os
import json
import io
import math
from pydub import AudioSegment
from google.cloud import speech
from google.oauth2 import service_account
from google import genai
from google.genai import types
from openai import OpenAI

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI èªéŸ³æ·¨åŒ–å™¨ (é€²éšæ··éŸ³ç‰ˆ)", page_icon="ğŸ›ï¸")
st.title("ğŸ›ï¸ AI èªéŸ³æ·¨åŒ–å™¨ - é€²éšç‰ˆ")
st.markdown("è‡ªå‹•åµæ¸¬è² é¢è©å½™ï¼Œä¸¦é€é **å‹•æ…‹è®Šé€Ÿ** èˆ‡ **ç½®ä¸­å°é½Š** é€²è¡Œå®Œç¾æ›¿æ›ã€‚")

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("ğŸ›ï¸ æ··éŸ³å¾®èª¿")
    manual_delay_ms = st.slider("æ‰‹å‹•å»¶é² (ms)", min_value=-500, max_value=500, value=0, step=10, help="æ­£æ•¸ä»£è¡¨å»¶å¾Œæ’­æ”¾ï¼Œè² æ•¸ä»£è¡¨ææ—©æ’­æ”¾")
    volume_boost = st.slider("æ›¿æ›éŸ³é‡å¢ç›Š (dB)", min_value=0, max_value=30, value=20, help="è®“æ›¿æ›çš„è²éŸ³æ¯”åŸéŸ³å¤§è²ä¸€é»")

# --- API è¨­å®šèˆ‡ Client åˆå§‹åŒ– ---
def get_secret(key):
    if key in st.secrets:
        return st.secrets[key]
    if os.getenv(key):
        return os.getenv(key)
    return None

try:
    # Google Cloud æ†‘è­‰
    if "google_cloud" in st.secrets:
        creds_dict = dict(st.secrets["google_cloud"])
        creds = service_account.Credentials.from_service_account_info(creds_dict)
        speech_client = speech.SpeechClient(credentials=creds)
    else:
        speech_client = speech.SpeechClient()

    # API Keys
    google_api_key = get_secret("GOOGLE_API_KEY")
    openai_api_key = get_secret("OPENAI_API_KEY")
    
    if not google_api_key or not openai_api_key:
        st.error("æ‰¾ä¸åˆ° API é‡‘é‘°ï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®šã€‚")
        st.stop()

    gemini_client = genai.Client(api_key=google_api_key)
    openai_client = OpenAI(api_key=openai_api_key)

except Exception as e:
    st.error(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
    st.stop()

# --- æ ¸å¿ƒé‚è¼¯: è®Šé€Ÿè™•ç† (ç§»æ¤è‡ªæ‚¨çš„ä»£ç¢¼) ---
def speed_change(sound, speed=1.0):
    # ä½¿ç”¨ frame_rate è¦†å¯«ä¾†æ”¹è®Šé€Ÿåº¦ (æœƒåŒæ™‚æ”¹è®ŠéŸ³é«˜ï¼Œé¡ä¼¼é»‘è† å”±ç‰‡åŠ é€Ÿ)
    # é€™æ˜¯æœ€è‡ªç„¶çš„è®Šé€Ÿæ–¹å¼ï¼Œä¸æœƒç”¢ç”Ÿæ•¸ä½é›œéŸ³
    sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={
        "frame_rate": int(sound.frame_rate * speed)
    })
    return sound_with_altered_frame_rate.set_frame_rate(sound.frame_rate)

# --- æ ¸å¿ƒé‚è¼¯: æ»‘å‹•è¦–çª—åŒ¹é… ---
def perform_sliding_window_match(asr_words: list, replacement_map: dict) -> list:
    final_logs = []
    i = 0
    n = len(asr_words)
    MAX_WINDOW_SIZE = 5

    while i < n:
        matched = False
        for window_size in range(min(MAX_WINDOW_SIZE, n - i), 0, -1):
            words_slice = asr_words[i : i + window_size]
            candidate_phrase = "".join([w['word'] for w in words_slice])
            
            if candidate_phrase in replacement_map:
                replacement_word = replacement_map[candidate_phrase]
                start_seconds = words_slice[0]['start_time'].total_seconds()
                end_seconds = words_slice[-1]['end_time'].total_seconds()
                
                duration = end_seconds - start_seconds
                
                # é€™è£¡åªåšç°¡å–®æ¨™è¨˜ï¼Œè©³ç´°è®Šé€Ÿåœ¨å¾Œé¢æ··éŸ³éšæ®µè™•ç†
                speed_instruction = "normal" 

                final_logs.append({
                    "original_word": candidate_phrase,
                    "replacement": replacement_word,
                    "start_time": start_seconds,
                    "end_time": end_seconds,
                    "duration_seconds": duration,
                    "speed_prompt": speed_instruction
                })
                i += window_size
                matched = True
                break
        if not matched:
            i += 1
    return final_logs

# --- ä¸»ä»‹é¢é‚è¼¯ ---
audio_input = st.audio_input("é»æ“Šéº¥å…‹é¢¨é–‹å§‹éŒ„éŸ³")

if audio_input is not None:
    if st.button("ğŸš€ é–‹å§‹æ·¨åŒ–è½‰æ›", type="primary"):
        status_text = st.empty()
        progress_bar = st.progress(0)

        try:
            # Step 1: ASR
            status_text.text("æ­£åœ¨è†è½ä¸¦è­˜åˆ¥èªéŸ³ (ASR)...")
            progress_bar.progress(10)
            
            audio_input.seek(0)
            audio_bytes = audio_input.read()
            
            audio = speech.RecognitionAudio(content=audio_bytes)
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED, 
                sample_rate_hertz=0, 
                language_code="zh-TW",
                enable_word_time_offsets=True,
                enable_automatic_punctuation=True,
            )

            operation = speech_client.recognize(config=config, audio=audio)
            
            if not operation.results:
                st.warning("æ²’æœ‰åµæ¸¬åˆ°æ¸…æ™°çš„èªéŸ³ã€‚")
                st.stop()

            result = operation.results[0].alternatives[0]
            transcript = result.transcript
            
            asr_words_data = []
            for word_info in result.words:
                asr_words_data.append({
                    "word": word_info.word.strip(),
                    "start_time": word_info.start_time,
                    "end_time": word_info.end_time
                })
            
            st.info(f"è­˜åˆ¥å…§å®¹: {transcript}")
            progress_bar.progress(30)

            # Step 2: LLM
            status_text.text("AI æ­£åœ¨å¯©æŸ¥æƒ…ç·’è©å½™...")
            
            schema = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "original_word": {"type": "string"},
                        "replacement_word": {"type": "string"}
                    },
                    "required": ["original_word", "replacement_word"]
                }
            }
            
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æƒ…ç·’è©å½™å¯©æŸ¥èˆ‡è½‰æ›å¼•æ“ã€‚
            ä»»å‹™ï¼šæ‰¾å‡ºè² é¢æƒ…ç·’è©å½™ä¸¦æ›¿æ›ç‚ºæ­£å‘ã€æ„è±¡ç¾å¥½çš„è©å½™ (å¦‚ï¼šå½©è™¹ã€èŠ±æœµã€æ³¡æ³¡ã€æ£‰èŠ±ç³–)ã€‚
            è¼¸å…¥æ–‡æœ¬: "{transcript}"
            """
            
            llm_response = gemini_client.models.generate_content(
                model='gemini-2.0-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=schema,
                )
            )
            censor_list = json.loads(llm_response.text)
            replacement_map = { item['original_word'].strip(): item['replacement_word'] for item in censor_list }
            
            if not replacement_map:
                st.success("æ²’æœ‰ç™¼ç¾è² é¢è©å½™ï¼")
                progress_bar.progress(100)
                st.stop()
                
            progress_bar.progress(50)

            # Step 3: åŒ¹é…èˆ‡æ··éŸ³
            timeline_rules = perform_sliding_window_match(asr_words_data, replacement_map)
            
            with st.expander("æŸ¥çœ‹è©³ç´°æ›¿æ›é‚è¼¯"):
                st.write(timeline_rules)

            status_text.text("æ­£åœ¨ç”ŸæˆèªéŸ³ä¸¦é€²è¡Œé€²éšæ··éŸ³...")
            
            # è¼‰å…¥åŸå§‹éŸ³è¨Š (pydub)
            try:
                original_audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
            except:
                original_audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="wav")

            # ç‚ºäº†é¿å…å¤šæ¬¡ç–ŠåŠ å°è‡´éŸ³é‡çˆ†éŸ³æˆ–éŒ¯ä½ï¼Œæˆ‘å€‘å»ºç«‹ä¸€å€‹ç©ºçš„éœéŸ³è»Œé“ä¾†æ”¾æ›¿æ›è©ï¼Œæœ€å¾Œå†ç–Šå›å»
            # æˆ–è€…ç›´æ¥åœ¨ original_audio ä¸Šæ“ä½œï¼ˆé€™è£¡æ¡ç”¨ç›´æ¥æ“ä½œï¼Œæ¯”è¼ƒç¬¦åˆæ‚¨çš„é‚è¼¯ï¼‰
            final_audio = original_audio

            for rule in timeline_rules:
                # 4-1. TTS ç”Ÿæˆ
                tts_resp = openai_client.audio.speech.create(
                    model="tts-1", voice="nova", input=rule['replacement']
                )
                replace_audio = AudioSegment.from_file(io.BytesIO(tts_resp.content), format="mp3")
                
                # 4-2. æ™‚é–“è¨ˆç®—
                original_start_ms = int(rule['start_time'] * 1000)
                original_end_ms = int(rule['end_time'] * 1000)
                original_duration_ms = original_end_ms - original_start_ms
                
                # 4-3. è®Šé€Ÿè™•ç†é‚è¼¯ (æ‚¨çš„æ ¸å¿ƒé‚è¼¯)
                current_len = len(replace_audio)
                
                # è¨ˆç®—éœ€è¦çš„é€Ÿåº¦ (è®“æ›¿æ›è©é•·åº¦ = åŸè©é•·åº¦)
                if original_duration_ms > 0:
                    calculated_speed = current_len / original_duration_ms
                else:
                    calculated_speed = 1.0
                
                # é™åˆ¶é€Ÿåº¦åœ¨ 0.8 ~ 1.2 ä¹‹é–“ï¼Œé¿å…è²éŸ³å¤ªå¥‡æ€ª
                speed_factor = max(0.8, min(calculated_speed, 1.2))
                
                # åŸ·è¡Œè®Šé€Ÿ
                adjusted_audio = speed_change(replace_audio, speed=speed_factor)
                
                # 4-4. éŸ³é‡å¢å¼·
                adjusted_audio = adjusted_audio + volume_boost
                
                
                # 4-6. ç½®ä¸­å°é½Šè¨ˆç®— (Centering Logic)
                # ç›®æ¨™ï¼šè®“ adjusted_audio çš„ä¸­å¿ƒé»ï¼Œå°é½ŠåŸæœ¬ç‰‡æ®µçš„ä¸­å¿ƒé»
                
                # åŸæœ¬ç‰‡æ®µçš„ä¸­å¿ƒé»
                original_center = (original_start_ms + original_end_ms) / 2
                
                # æ–°ç‰‡æ®µçš„ä¸€åŠé•·åº¦
                half_new_duration = len(adjusted_audio) / 2
                
                # è¨ˆç®—æ–°çš„é–‹å§‹æ™‚é–“ = ä¸­å¿ƒé» - æ–°ç‰‡æ®µçš„ä¸€åŠ + æ‰‹å‹•å»¶é²
                final_position_ms = int(original_center)
                
                # é˜²å‘†ï¼šä¸èƒ½å°æ–¼ 0
                final_position_ms = max(0, final_position_ms)
                
                # 4-7. ç–ŠåŠ  (Overlay)
                final_audio = final_audio.overlay(adjusted_audio, position=final_position_ms)

            progress_bar.progress(100)
            status_text.text("âœ¨ è™•ç†å®Œæˆï¼")
            st.balloons()
            
            # è¼¸å‡ºçµæœ
            buffer = io.BytesIO()
            final_audio.export(buffer, format="mp3")
            final_audio_bytes = buffer.getvalue()
            
            st.subheader("ğŸ§ æ·¨åŒ–å¾Œçš„è²éŸ³")
            st.audio(final_audio_bytes, format='audio/mpeg')
            
            st.download_button(
                label="ä¸‹è¼‰ MP3",
                data=final_audio_bytes,
                file_name="censored_remix.mp3",
                mime="audio/mpeg"
            )

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

