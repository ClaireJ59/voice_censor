import streamlit as st
import os
import json
import io
import requests
import tempfile
from google.cloud import speech
from google.oauth2 import service_account
from google import genai
from google.genai import types
from openai import OpenAI

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI èªéŸ³æ·¨åŒ–å™¨", page_icon="âœ¨")
st.title("âœ¨ AI èªéŸ³æƒ…ç·’æ·¨åŒ–å™¨")
st.markdown("ä¸Šå‚³ä¸€æ®µèªéŸ³ï¼ŒAI å°‡è‡ªå‹•è­˜åˆ¥è² é¢è©å½™ä¸¦æ›¿æ›ç‚ºç¾å¥½çš„è©èªã€‚")

# --- å´é‚Šæ¬„ï¼šAPI è¨­å®š (æœ¬åœ°æ¸¬è©¦ç”¨ .envï¼Œé›²ç«¯ç”¨ st.secrets) ---
# ç‚ºäº†æ–¹ä¾¿éƒ¨ç½²ï¼Œæˆ‘å€‘å„ªå…ˆæª¢æŸ¥ st.secretsï¼Œå¦‚æœæ²’æœ‰å‰‡å˜—è©¦ç’°å¢ƒè®Šæ•¸
# å®šç¾©ä¸€å€‹è®€å–é‡‘é‘°çš„å‡½æ•¸ï¼Œå„ªå…ˆæŸ¥ Secretsï¼Œæ²’æœ‰æ‰æŸ¥ç³»çµ±è®Šæ•¸
def get_secret(key):
    if key in st.secrets:
        return st.secrets[key]
    if os.getenv(key):
        return os.getenv(key)
    return None # æˆ–æ˜¯æ‹‹å‡ºéŒ¯èª¤

# ç²å–é‡‘é‘°
google_api_key = get_secret("GOOGLE_API_KEY")
openai_api_key = get_secret("OPENAI_API_KEY")

# æª¢æŸ¥æ˜¯å¦æˆåŠŸç²å– (é€™ä¸€æ­¥å¾ˆé‡è¦ï¼Œå¯ä»¥é¿å…å ±å‡ºé›£æ‡‚çš„éŒ¯èª¤)
if not google_api_key:
    st.error("æ‰¾ä¸åˆ° GOOGLE_API_KEYï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®šã€‚")
    st.stop()

if not openai_api_key:
    st.error("æ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®šã€‚")
    st.stop()

# åˆå§‹åŒ– Client
gemini_client = genai.Client(api_key=google_api_key)
openai_client = OpenAI(api_key=openai_api_key)

# --- æ ¸å¿ƒé‚è¼¯å‡½æ•¸ (å¿«å–ä»¥æå‡æ•ˆèƒ½) ---
# 1. åˆå§‹åŒ– Google ASR Client
@st.cache_resource
def get_speech_client():
    # å˜—è©¦å¾ secrets è®€å– Google Cloud JSON å…§å®¹
    if "google_cloud" in st.secrets:
        # å°‡ secrets è½‰æ›ç‚º dict
        creds_dict = dict(st.secrets["google_cloud"])
        creds = service_account.Credentials.from_service_account_info(creds_dict)
        return speech.SpeechClient(credentials=creds)
    else:
        # æœ¬åœ°é–‹ç™¼å¦‚æœè¨­å®šäº†ç’°å¢ƒè®Šæ•¸è·¯å¾‘
        return speech.SpeechClient()

# 2. åˆå§‹åŒ–å…¶ä»– Clients
try:
    speech_client = get_speech_client()
    gemini_client = genai.Client(api_key=get_secret("GOOGLE_API_KEY"))
    openai_client = OpenAI(api_key=get_secret("OPENAI_API_KEY"))
except Exception as e:
    st.error(f"API åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®š: {e}")
    st.stop()

EXTERNAL_MIX_URL = "https://a67e4a6a0969.ngrok-free.app/mix"

# --- è¼”åŠ©å‡½æ•¸ï¼šæ»‘å‹•è¦–çª—åŒ¹é… ---
def perform_sliding_window_match(asr_words: list, replacement_map: dict) -> list:
    final_logs = []
    i = 0
    n = len(asr_words)
    MAX_WINDOW_SIZE = 5

    while i < n:
        matched = False
        for window_size in range(min(MAX_WINDOW_SIZE, n - i), 0, -1):
            words_slice = asr_words[i : i + window_size]
            candidate_phrase = "".join([w['word'] for w in words_slice])
            
            if candidate_phrase in replacement_map:
                replacement_word = replacement_map[candidate_phrase]
                start_seconds = words_slice[0]['start_time'].total_seconds()
                end_seconds = words_slice[-1]['end_time'].total_seconds()
                
                duration = end_seconds - start_seconds + 1.5
                if duration <= 0: duration = 0.5
                
                speed_instruction = "normal"
                if duration < 0.4: speed_instruction = "fast"
                elif duration > 1.5: speed_instruction = "slow"

                final_logs.append({
                    "original_word": candidate_phrase,
                    "replacement": replacement_word,
                    "start_time": f"{start_seconds}s",
                    "end_time": f"{end_seconds}s",
                    "duration_seconds": duration,
                    "speed_prompt": speed_instruction
                })
                i += window_size
                matched = True
                break
        if not matched:
            i += 1
    return final_logs

# --- ä¸»ä»‹é¢ ---
st.subheader("è«‹é¸æ“‡è¼¸å…¥æ–¹å¼")

# å»ºç«‹å…©å€‹åˆ†é ï¼šéŒ„éŸ³ vs ä¸Šå‚³
tab1, tab2 = st.tabs(["ğŸ¤ ç¾å ´éŒ„éŸ³", "ğŸ“‚ ä¸Šå‚³æª”æ¡ˆ"])

audio_input = None
source_type = ""

# åˆ†é  1: éŒ„éŸ³
with tab1:
    recorded_audio = st.audio_input("é»æ“Šä¸‹æ–¹éº¥å…‹é¢¨é–‹å§‹éŒ„éŸ³")
    if recorded_audio:
        audio_input = recorded_audio
        source_type = "recording"

# åˆ†é  2: ä¸Šå‚³
with tab2:
    uploaded_file = st.file_uploader("é¸æ“‡éŸ³è¨Šæª”æ¡ˆ", type=["wav", "mp3", "webm", "m4a"])
    if uploaded_file:
        audio_input = uploaded_file
        source_type = "upload"

# --- é–‹å§‹è™•ç†é‚è¼¯ ---
# åªæœ‰ç•¶åµæ¸¬åˆ°æœ‰éŸ³è¨Šè¼¸å…¥ (ä¸è«–æ˜¯éŒ„éŸ³é‚„æ˜¯ä¸Šå‚³) æ‰é¡¯ç¤ºæŒ‰éˆ•
if audio_input is not None:
    # é å…ˆæ’­æ”¾çµ¦ä½¿ç”¨è€…è½
    st.audio(audio_input, format='audio/wav') # éŒ„éŸ³é è¨­æ˜¯ wav
    
    if st.button("ğŸš€ é–‹å§‹è½‰æ›", type="primary"):
        status_text = st.empty()
        progress_bar = st.progress(0)

        try:
            # Step 1: è®€å–æª”æ¡ˆèˆ‡ ASR
            status_text.text("æ­£åœ¨é€²è¡ŒèªéŸ³è­˜åˆ¥ (ASR)...")
            progress_bar.progress(10)
            
            # è®€å– bytes
            # æ³¨æ„: st.audio_input å›å‚³çš„æŒ‡é‡å¯èƒ½åœ¨æœ€å¾Œï¼Œå»ºè­°å…ˆ seek(0)
            audio_input.seek(0)
            audio_content = audio_input.read()
            
            audio = speech.RecognitionAudio(content=audio_content)
            
            # [é‡è¦ä¿®æ”¹] æ›´æ”¹ ASR Config ä»¥å…¼å®¹éŒ„éŸ³æª”(WAV)å’Œä¸Šå‚³æª”
            # ç€è¦½å™¨éŒ„éŸ³é€šå¸¸æ˜¯ WAV (Linear PCM)ï¼Œä¸èƒ½å¼·åˆ¶è¨­ç‚º WEBM_OPUS
            config = speech.RecognitionConfig(
                # è¨­å®šç‚º UNSPECIFIED è®“ Google è‡ªå‹•å˜—è©¦åµæ¸¬æ ¼å¼
                encoding=speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED, 
                sample_rate_hertz=48000, # å¤§å¤šæ•¸ç€è¦½å™¨éŒ„éŸ³ç‚º 44100 æˆ– 48000ï¼ŒGoogle é€šå¸¸èƒ½é©æ‡‰
                language_code="zh-TW",
                enable_word_time_offsets=True,
                enable_automatic_punctuation=True,
            )

            operation = speech_client.recognize(config=config, audio=audio)
            
            if not operation.results:
                st.error("ç„¡æ³•è­˜åˆ¥èªéŸ³ï¼Œå¯èƒ½æ˜¯éº¥å…‹é¢¨æ”¶éŸ³å¤ªå°è²æˆ–æ ¼å¼ä¸æ”¯æ´ã€‚")
                st.stop()

            # ... (ä»¥ä¸‹çš„ç¨‹å¼ç¢¼é‚è¼¯ä¿æŒä¸è®Šï¼Œç›´æ¥è¤‡è£½åŸæœ¬çš„å³å¯) ...
            result = operation.results[0].alternatives[0]
            transcript = result.transcript

            # Step 2: LLM åˆ¤æ–·
            status_text.text("AI æ­£åœ¨å¯©æŸ¥æƒ…ç·’è©å½™...")
            
            schema = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "original_word": {"type": "string"},
                        "replacement_word": {"type": "string"}
                    },
                    "required": ["original_word", "replacement_word"]
                }
            }
            
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æƒ…ç·’è©å½™å¯©æŸ¥èˆ‡è½‰æ›å¼•æ“ã€‚
            ä»»å‹™ï¼šæ‰¾å‡ºè² é¢æƒ…ç·’è©å½™ä¸¦æ›¿æ›ç‚ºæ­£å‘ã€æ„è±¡ç¾å¥½çš„è©å½™ (å¦‚ï¼šå½©è™¹ã€èŠ±æœµã€æ³¡æ³¡)ã€‚
            è¼¸å…¥æ–‡æœ¬: "{transcript}"
            """
            
            llm_response = gemini_client.models.generate_content(
                model='gemini-2.0-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=schema,
                )
            )
            censor_list = json.loads(llm_response.text)
            replacement_map = { item['original_word'].strip(): item['replacement_word'] for item in censor_list }
            
            if not replacement_map:
                st.success("æ²’æœ‰æª¢æ¸¬åˆ°è² é¢è©å½™ï¼")
                st.stop()
                
            progress_bar.progress(50)

            # Step 3: åŒ¹é…æ™‚é–“è»¸
            timeline_rules = perform_sliding_window_match(asr_words_data, replacement_map)
            st.write("æ›¿æ›è¨ˆåŠƒ:", timeline_rules)

            # Step 4: TTS ç”Ÿæˆ
            status_text.text("æ­£åœ¨ç”Ÿæˆæ›¿æ›éŸ³è¨Š (TTS)...")
            tts_files = {}
            for idx, rule in enumerate(timeline_rules):
                speed = 1.0
                if rule['speed_prompt'] == 'fast': speed = 1.2
                elif rule['speed_prompt'] == 'slow': speed = 0.8
                
                resp = openai_client.audio.speech.create(
                    model="tts-1", voice="nova", input=rule['replacement'], speed=speed
                )
                tts_files[f"replacement_{idx}"] = (f"rep_{idx}.mp3", io.BytesIO(resp.content), "audio/mpeg")
            
            # Padding
            for i in range(5):
                key = f"replacement_{i}"
                if key not in tts_files:
                    tts_files[key] = ('dummy.bin', io.BytesIO(b'dummy'), 'application/octet-stream')
            
            progress_bar.progress(70)

            # Step 5: æ··éŸ³
            status_text.text("æ­£åœ¨é€²è¡Œæœ€çµ‚æ··éŸ³...")
            uploaded_file.seek(0)
            
            censor_rules_json = json.dumps([{
                "replacement": r['replacement'],
                "start_time": r['start_time'],
                "end_time": r['end_time']
            } for r in timeline_rules])

            files_to_upload = {
                'original_audio': (uploaded_file.name, uploaded_file, uploaded_file.type),
                **tts_files
            }
            
            mix_response = requests.post(
                EXTERNAL_MIX_URL,
                data={'censor_rules': censor_rules_json},
                files=files_to_upload
            )

            if mix_response.status_code == 200:
                progress_bar.progress(100)
                status_text.text("å®Œæˆï¼")
                st.success("è½‰æ›æˆåŠŸï¼")
                
                # å±•ç¤ºèˆ‡ä¸‹è¼‰
                st.audio(mix_response.content, format='audio/mpeg')
                st.download_button(
                    label="ä¸‹è¼‰è™•ç†å¾Œçš„éŸ³è¨Š",
                    data=mix_response.content,
                    file_name="censored_audio.mp3",
                    mime="audio/mpeg"
                )
            else:
                st.error(f"æ··éŸ³æœå‹™éŒ¯èª¤: {mix_response.text}")

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
